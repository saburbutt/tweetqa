{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainingtweetqa_xlnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d4da5e6262647efa3f5ce0e6f4b10db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96e3dac5e08e417a9e7b8a662932ce76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c62f38be78d1439d88f8db761826daa0",
              "IPY_MODEL_4b4fd735e65c4ef380fa38d1ffc24943"
            ]
          }
        },
        "96e3dac5e08e417a9e7b8a662932ce76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c62f38be78d1439d88f8db761826daa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8570b2d595c5411db20c1a139b190401",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4ab8156558c4cc898e62addf353f546"
          }
        },
        "4b4fd735e65c4ef380fa38d1ffc24943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0c3ed2199e1487f8d2f81f7c8c97778",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:01&lt;00:00, 627kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a602d377c8246d788c810162f91ca2b"
          }
        },
        "8570b2d595c5411db20c1a139b190401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4ab8156558c4cc898e62addf353f546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0c3ed2199e1487f8d2f81f7c8c97778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a602d377c8246d788c810162f91ca2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b617ce4c6a49450abaa6123b615b7904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09df2d9d2ec946d8ae7444497d320551",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce2683968f3a407a8fd205ebd83dc408",
              "IPY_MODEL_eda97ab35d4c48afbb89669964e6a311"
            ]
          }
        },
        "09df2d9d2ec946d8ae7444497d320551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce2683968f3a407a8fd205ebd83dc408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a86240cb339f436a8e9cddff7e1eadda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1382015,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1382015,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d4686aebf6b48cd95dc1fb7c1e31950"
          }
        },
        "eda97ab35d4c48afbb89669964e6a311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3a229ddd4ec48f4b394f9e22b700895",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.38M/1.38M [00:01&lt;00:00, 1.35MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7ba0738f2d9429f9353eeafe10b0120"
          }
        },
        "a86240cb339f436a8e9cddff7e1eadda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d4686aebf6b48cd95dc1fb7c1e31950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3a229ddd4ec48f4b394f9e22b700895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7ba0738f2d9429f9353eeafe10b0120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a6468165e4a4388b92f76d848ae7eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0a4d6b344b54a95ae8ca072a5a4f6d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a3180b6743143a7bec95e5053d20e20",
              "IPY_MODEL_6a07f48b7387427b9fb4634d700cccfa"
            ]
          }
        },
        "a0a4d6b344b54a95ae8ca072a5a4f6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a3180b6743143a7bec95e5053d20e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9891549aa0f84f239ba213f7df3edc08",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32bc7ae939284a759dcdb14411785f8f"
          }
        },
        "6a07f48b7387427b9fb4634d700cccfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8900ad3ab90e440d99027779f5a24b16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 761/761 [00:00&lt;00:00, 868B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f7ec062f2e2455780adf3e71d02ffb6"
          }
        },
        "9891549aa0f84f239ba213f7df3edc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32bc7ae939284a759dcdb14411785f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8900ad3ab90e440d99027779f5a24b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f7ec062f2e2455780adf3e71d02ffb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99120d913418443e95bbe0f44a6c3343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9f7b5c695fa4ceb88c7b01b3dc209c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_045439c2fb0a4e749f864990321cffac",
              "IPY_MODEL_aada9c27cf4d488db928ed12b2d74e6b"
            ]
          }
        },
        "b9f7b5c695fa4ceb88c7b01b3dc209c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "045439c2fb0a4e749f864990321cffac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc9a9e65e8a2445e94e307e826e9504b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1441285815,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1441285815,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bce964d658546d3bf1b589da99766fe"
          }
        },
        "aada9c27cf4d488db928ed12b2d74e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1045f2b5516b4cdb882a419f0f4c9daa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.44G/1.44G [00:28&lt;00:00, 50.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a40d678c3df41de8bbf1df91009a4fd"
          }
        },
        "fc9a9e65e8a2445e94e307e826e9504b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bce964d658546d3bf1b589da99766fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1045f2b5516b4cdb882a419f0f4c9daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a40d678c3df41de8bbf1df91009a4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saburbutt/tweetqa/blob/master/trainingtweetqa_xlnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_YvqmuAVv7D",
        "outputId": "a67d9ab9-5002-4fe5-8652-00f8d2b04769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install transformers\n",
        "! pip install torch\n",
        "#%cd \"/content/albert_xxlarge_tweetqa\"\n",
        "! pip install git-lfs install\n",
        "#!git lfs install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=22686f780ed526622aae76922dc6153d5faabbda691706f8285c69e5c2a598ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git-lfs\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/40/cd243be7ba9bd9d83fd8515b1aed7e0b822c76cab4bf60398a1b7e024f00/git_lfs-1.6-py2.py3-none-any.whl\n",
            "Collecting install\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/a5/fd2eb807a9a593869ee8b7a6bcb4ad84a6eb31cef5c24d1bfbf7c938c13f/install-1.3.4-py3-none-any.whl\n",
            "Installing collected packages: git-lfs, install\n",
            "Successfully installed git-lfs-1.6 install-1.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--tnazUPWZNT",
        "outputId": "f5c6a22f-ae7e-4500-9b4e-69ba20fb51b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! transformers-cli login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-16 00:09:30.779056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: saboor.butt007@gmail.com\n",
            "Password: \n",
            "Login successful\n",
            "Your token: lNqOTtqpnkgTvsvOZOoRlolpSilcLZrBHmfUkSZHBSaknMTdOXVQgJvOdGoEoVYseVSJbMvGAHJLzOYPhhecvoxNqeKUixIOgQAtNVffPKItqEERFbItErQYiIqoQkRv \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxOguxuIcwtJ"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "    \n",
        "  \n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    \"\"\"for qs in squad_dict[\"data\"]:\n",
        "      for qas in qs[\"paragraphs\"]:\n",
        "        #print(qas[\"context\"])\n",
        "        #print(qas)\n",
        "        context = qas['context']\n",
        "        #print(context)\n",
        "        for quest in qas['qas']:\n",
        "          print(quest)\"\"\"\n",
        "         \n",
        "        \n",
        "    #question = qs[\"Question\"]\n",
        "    #answer = qs[\"Answer\"]\n",
        "    #context = qs[\"Tweet\"]\n",
        "    #print(question, answer[0:], context)\n",
        "    #contexts.append((qs[\"Tweet\"])\n",
        "    #questions.append(qs[\"Question\"])\n",
        "    #answers.append(qs[\"Answer\"])\n",
        "      \n",
        "    \n",
        "    \n",
        "    \n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "  \n",
        "\n",
        "#train_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3ZjCyqYGmGw",
        "outputId": "8827e97d-806f-4de1-ed5b-4b7838168d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "\"\"\"import json\n",
        "from pathlib import Path\n",
        "\n",
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "train_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import json\\nfrom pathlib import Path\\n\\ndef read_squad(path):\\n    path = Path(path)\\n    with open(path, 'rb') as f:\\n        squad_dict = json.load(f)\\n\\n    contexts = []\\n    questions = []\\n    answers = []\\n    for group in squad_dict['data']:\\n        for passage in group['paragraphs']:\\n            context = passage['context']\\n            for qa in passage['qas']:\\n                question = qa['question']\\n                for answer in qa['answers']:\\n                    contexts.append(context)\\n                    questions.append(question)\\n                    answers.append(answer)\\n\\n    return contexts, questions, answers\\n\\ntrain_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\\nval_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnLWnos6FGqd",
        "outputId": "2857bed0-0773-4b1d-d380-16854aa874be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"print(train_contexts[0])\n",
        "print(train_questions[0])\n",
        "print(train_answers[0])\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print(train_contexts[0])\\nprint(train_questions[0])\\nprint(train_answers[0])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQlttoPOSpUO",
        "outputId": "45548027-cc54-48d5-df71-f659b21ee49e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(val_contexts[0])\n",
        "print(val_questions[0])\n",
        "print(val_answers[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
            "In what country is Normandy located?\n",
            "{'text': 'France', 'answer_start': 159}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ENYEcr7SspA"
      },
      "source": [
        "import json\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ucBE35HSumO"
      },
      "source": [
        "def extract_element_from_json(obj, path):\n",
        "    '''\n",
        "    Extracts an element from a nested dictionary or\n",
        "    a list of nested dictionaries along a specified path.\n",
        "    If the input is a dictionary, a list is returned.\n",
        "    If the input is a list of dictionary, a list of lists is returned.\n",
        "    obj - list or dict - input dictionary or list of dictionaries\n",
        "    path - list - list of strings that form the path to the desired element\n",
        "    '''\n",
        "    def extract(obj, path, ind, arr):\n",
        "        '''\n",
        "            Extracts an element from a nested dictionary\n",
        "            along a specified path and returns a list.\n",
        "            obj - dict - input dictionary\n",
        "            path - list - list of strings that form the JSON path\n",
        "            ind - int - starting index\n",
        "            arr - list - output list\n",
        "        '''\n",
        "        key = path[ind]\n",
        "        if ind + 1 < len(path):\n",
        "            if isinstance(obj, dict):\n",
        "                if key in obj.keys():\n",
        "                    extract(obj.get(key), path, ind + 1, arr)\n",
        "                else:\n",
        "                    arr.append(None)\n",
        "            elif isinstance(obj, list):\n",
        "                if not obj:\n",
        "                    arr.append(None)\n",
        "                else:\n",
        "                    for item in obj:\n",
        "                        extract(item, path, ind, arr)\n",
        "            else:\n",
        "                arr.append(None)\n",
        "        if ind + 1 == len(path):\n",
        "            if isinstance(obj, list):\n",
        "                if not obj:\n",
        "                    arr.append(None)\n",
        "                else:\n",
        "                    for item in obj:\n",
        "                        arr.append(item.get(key, None))\n",
        "            elif isinstance(obj, dict):\n",
        "                arr.append(obj.get(key, None))\n",
        "            else:\n",
        "                arr.append(None)\n",
        "        return arr\n",
        "    if isinstance(obj, dict):\n",
        "        return extract(obj, path, 0, [])\n",
        "    elif isinstance(obj, list):\n",
        "        outer_arr = []\n",
        "        for item in obj:\n",
        "            outer_arr.append(extract(item, path, 0, []))\n",
        "        return outer_arr\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiuX1fgRSwq2"
      },
      "source": [
        "def list_flatten(l):\n",
        "    result = list()\n",
        "    for item in l:\n",
        "        if isinstance(item, (list, tuple)):\n",
        "            result.extend(item)\n",
        "        else:\n",
        "            result.append(item)\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVpHr2oSyao"
      },
      "source": [
        "class All_Data:  \n",
        "    def __init__(self, qas, context):  \n",
        "        self.qas = qas\n",
        "        self.context = context\n",
        "\n",
        "        \n",
        "class Questions:  \n",
        "    def __init__(self, question, answer, _id, is_impossible ):  \n",
        "        self.question = question  \n",
        "        self._id = _id \n",
        "        self.answer = answer \n",
        "        self.is_impossible = is_impossible\n",
        "                \n",
        "\n",
        "class Answers:  \n",
        "    def __init__(self, text, answer_start):  \n",
        "        self.text = text  \n",
        "        self.answer_start = answer_start     \n",
        "        "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BRNPspS08m",
        "outputId": "f02e7e69-8901-4a1f-c554-c9cf061770fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "with open('results.json', 'r') as file:\n",
        "    all_data = json.load(file)\n",
        "    print(len(all_data))\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWAVVCZsS5LJ"
      },
      "source": [
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "\n",
        "counting = 0\n",
        "\n",
        "for data in all_data:\n",
        "    context = ''.join(extract_element_from_json(data, [\"context\"]))\n",
        "    que = list_flatten(list_flatten(extract_element_from_json(data, [\"qas\"])))\n",
        "\n",
        "    for q in que:\n",
        "        ans = extract_element_from_json(q, [\"answer\"])\n",
        "        #print(ans)\n",
        "        for a in ans:\n",
        "            #print(a['text'])\n",
        "            #print(a['answer_start'])\n",
        "            if not a['answer_start'] == 0:\n",
        "                #print(context.lower())\n",
        "                #print(q['question'].lower())\n",
        "                #print(q['answer'])\n",
        "                contexts.append(context.lower())\n",
        "                questions.append(q['question'].lower())\n",
        "                answers.append(q['answer'])\n",
        "            \n",
        "\n",
        "    #print(\"\\n\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzLBOMwTS7Nw"
      },
      "source": [
        "train_contexts = contexts\n",
        "train_questions = questions\n",
        "train_answers = answers"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bMgS8XS83H",
        "outputId": "0510f55a-27cc-44f9-f79b-c614ce75f41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_contexts[0])\n",
        "print(train_questions[0])\n",
        "print(train_answers[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our prayers are with the students, educators & families at independence high school & all the first responders on the scene. #patriotpride— doug ducey (@dougducey) february 12, 2016\n",
            "at which school were first responders on the scene for?\n",
            "{'text': 'independence high school', 'answer_start': 59}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhavDW55At59"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UAWEpQ1dygO"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        #print(answer['text'])\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "        #print(gold_text)\n",
        "        #print(start_idx)\n",
        "        #print(end_idx)\n",
        "        #print(\"\\n\")\n",
        "\n",
        "        # sometimes squad answers are off by a character or two – fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo5s9XnEd5ld",
        "outputId": "86fd56f2-ccc1-419b-f90d-458e77b49a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "7d4da5e6262647efa3f5ce0e6f4b10db",
            "96e3dac5e08e417a9e7b8a662932ce76",
            "c62f38be78d1439d88f8db761826daa0",
            "4b4fd735e65c4ef380fa38d1ffc24943",
            "8570b2d595c5411db20c1a139b190401",
            "c4ab8156558c4cc898e62addf353f546",
            "f0c3ed2199e1487f8d2f81f7c8c97778",
            "4a602d377c8246d788c810162f91ca2b",
            "b617ce4c6a49450abaa6123b615b7904",
            "09df2d9d2ec946d8ae7444497d320551",
            "ce2683968f3a407a8fd205ebd83dc408",
            "eda97ab35d4c48afbb89669964e6a311",
            "a86240cb339f436a8e9cddff7e1eadda",
            "8d4686aebf6b48cd95dc1fb7c1e31950",
            "d3a229ddd4ec48f4b394f9e22b700895",
            "f7ba0738f2d9429f9353eeafe10b0120"
          ]
        }
      },
      "source": [
        "#from transformers import DistilBertTokenizerFast\n",
        "#from transformers import AlbertTokenizerFast\n",
        "from transformers import XLNetTokenizerFast\n",
        "#from transformers import RobertaTokenizerFast\n",
        "#from transformers import XLMRobertaTokenizerFast\n",
        "import torch\n",
        "#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "#tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "#tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')\n",
        "#tokenizer = AlbertTokenizerFast.from_pretrained('albert-xxlarge-v2')\n",
        "#tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")\n",
        "#tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-large\")\n",
        "#xlm-roberta-large\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-large-cased')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4da5e6262647efa3f5ce0e6f4b10db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b617ce4c6a49450abaa6123b615b7904",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnlCx12AFyKQ",
        "outputId": "36bf1752-b6ce-4074-e7c1-ce35d00c92c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_encodings[0])\n",
        "print(val_encodings[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "Encoding(num_tokens=838, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXO_rEpueH6O"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        #print(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        #print(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        # if None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "        #print(\"\\n\")\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkLAW7jeUXS"
      },
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ5Ldsamewug",
        "outputId": "aadb777e-fd71-4292-d482-3bb70546f789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "1a6468165e4a4388b92f76d848ae7eea",
            "a0a4d6b344b54a95ae8ca072a5a4f6d5",
            "5a3180b6743143a7bec95e5053d20e20",
            "6a07f48b7387427b9fb4634d700cccfa",
            "9891549aa0f84f239ba213f7df3edc08",
            "32bc7ae939284a759dcdb14411785f8f",
            "8900ad3ab90e440d99027779f5a24b16",
            "8f7ec062f2e2455780adf3e71d02ffb6",
            "99120d913418443e95bbe0f44a6c3343",
            "b9f7b5c695fa4ceb88c7b01b3dc209c9",
            "045439c2fb0a4e749f864990321cffac",
            "aada9c27cf4d488db928ed12b2d74e6b",
            "fc9a9e65e8a2445e94e307e826e9504b",
            "4bce964d658546d3bf1b589da99766fe",
            "1045f2b5516b4cdb882a419f0f4c9daa",
            "2a40d678c3df41de8bbf1df91009a4fd"
          ]
        }
      },
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "from transformers import AlbertForQuestionAnswering\n",
        "from transformers import XLNetForQuestionAnswering\n",
        "from transformers import RobertaForQuestionAnswering\n",
        "from transformers import XLMRobertaForQuestionAnswering\n",
        "#model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
        "#model = AlbertForQuestionAnswering.from_pretrained('albert-large-v2')\n",
        "#model = AlbertForQuestionAnswering.from_pretrained('albert-xxlarge-v2')\n",
        "#model = XLNetForQuestionAnswering.from_pretrained('xlnet-base-cased')\n",
        "#model = RobertaForQuestionAnswering.from_pretrained('roberta-base' , from_tf=True)\n",
        "model = XLNetForQuestionAnswering.from_pretrained('xlnet-large-cased')\n",
        "#model = RobertaForQuestionAnswering.from_pretrained('roberta-large')\n",
        "#model = XLMRobertaForQuestionAnswering.from_pretrained('xlm-roberta-large')\n",
        "#xlm-roberta-large\n",
        "#roberta-large\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a6468165e4a4388b92f76d848ae7eea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=761.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99120d913418443e95bbe0f44a6c3343",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1441285815.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-large-cased were not used when initializing XLNetForQuestionAnswering: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForQuestionAnswering were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['start_logits.dense.weight', 'start_logits.dense.bias', 'end_logits.dense_0.weight', 'end_logits.dense_0.bias', 'end_logits.LayerNorm.weight', 'end_logits.LayerNorm.bias', 'end_logits.dense_1.weight', 'end_logits.dense_1.bias', 'answer_class.dense_0.weight', 'answer_class.dense_0.bias', 'answer_class.dense_1.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNPJTqzZfys7",
        "outputId": "c49ee5cf-2188-4198-ba94-5a9620242cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0.alpha0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.18.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.33.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 70.3MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.10.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0.alpha0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0.alpha0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (3.4.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-applications, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Y-vBp1e1NR",
        "outputId": "4ff3bb08-4d94-43c2-d7a0-a256dc475663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "i = 0\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 10 == 0:\n",
        "          print(i, \"Done\")\n",
        "        i = i + 1\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "0 Done\n",
            "10 Done\n",
            "20 Done\n",
            "30 Done\n",
            "40 Done\n",
            "50 Done\n",
            "60 Done\n",
            "70 Done\n",
            "80 Done\n",
            "90 Done\n",
            "100 Done\n",
            "110 Done\n",
            "120 Done\n",
            "130 Done\n",
            "140 Done\n",
            "150 Done\n",
            "160 Done\n",
            "170 Done\n",
            "180 Done\n",
            "190 Done\n",
            "200 Done\n",
            "210 Done\n",
            "220 Done\n",
            "230 Done\n",
            "240 Done\n",
            "250 Done\n",
            "260 Done\n",
            "270 Done\n",
            "280 Done\n",
            "290 Done\n",
            "300 Done\n",
            "310 Done\n",
            "320 Done\n",
            "330 Done\n",
            "340 Done\n",
            "350 Done\n",
            "360 Done\n",
            "370 Done\n",
            "380 Done\n",
            "390 Done\n",
            "400 Done\n",
            "410 Done\n",
            "420 Done\n",
            "430 Done\n",
            "440 Done\n",
            "450 Done\n",
            "460 Done\n",
            "470 Done\n",
            "480 Done\n",
            "490 Done\n",
            "500 Done\n",
            "510 Done\n",
            "520 Done\n",
            "530 Done\n",
            "540 Done\n",
            "550 Done\n",
            "560 Done\n",
            "570 Done\n",
            "580 Done\n",
            "590 Done\n",
            "600 Done\n",
            "610 Done\n",
            "620 Done\n",
            "630 Done\n",
            "640 Done\n",
            "650 Done\n",
            "660 Done\n",
            "670 Done\n",
            "680 Done\n",
            "690 Done\n",
            "700 Done\n",
            "710 Done\n",
            "720 Done\n",
            "730 Done\n",
            "740 Done\n",
            "750 Done\n",
            "760 Done\n",
            "770 Done\n",
            "780 Done\n",
            "790 Done\n",
            "800 Done\n",
            "810 Done\n",
            "820 Done\n",
            "830 Done\n",
            "840 Done\n",
            "850 Done\n",
            "860 Done\n",
            "870 Done\n",
            "880 Done\n",
            "890 Done\n",
            "900 Done\n",
            "910 Done\n",
            "920 Done\n",
            "930 Done\n",
            "940 Done\n",
            "950 Done\n",
            "960 Done\n",
            "970 Done\n",
            "980 Done\n",
            "990 Done\n",
            "1000 Done\n",
            "1010 Done\n",
            "1020 Done\n",
            "1030 Done\n",
            "1040 Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForQuestionAnswering(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 1024)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (12): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (13): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (14): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (15): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (16): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (17): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (18): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (19): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (20): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (21): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (22): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (23): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (start_logits): PoolerStartLogits(\n",
              "    (dense): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              "  (end_logits): PoolerEndLogits(\n",
              "    (dense_0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dense_1): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              "  (answer_class): PoolerAnswerClass(\n",
              "    (dense_0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (dense_1): Linear(in_features=1024, out_features=1, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMHtgaUAXJaQ"
      },
      "source": [
        "# Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejtiRpQ1tn5N",
        "outputId": "be18fe21-16fd-490d-a757-e0be1dbf9767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"! pip install joblib\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'! pip install joblib'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTadVwCLvtKi",
        "outputId": "4d6068e8-bb74-4d93-a213-62d6a3313a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"import joblib\n",
        "filename = 'xlm-roberta_large_tweetqa_model.sav'\n",
        "joblib.dump(model, filename)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import joblib\\nfilename = 'xlm-roberta_large_tweetqa_model.sav'\\njoblib.dump(model, filename)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJr46lg-CAS",
        "outputId": "425af2ad-c19c-4300-e029-fcbd60ad9596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! transformers-cli repo create xlnet_large_tweetqa\n",
        "#! transformers-cli repo ls-files testing"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-16 00:22:09.037016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[90mgit version 2.17.1\u001b[0m\n",
            "\u001b[1m\u001b[31mLooks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once).\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1msaburbutt/xlnet_large_tweetqa\u001b[0m\n",
            "Proceed? [Y/n] Y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/saburbutt/xlnet_large_tweetqa\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/saburbutt/xlnet_large_tweetqa\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaerK0u5TWm",
        "outputId": "c9ca6906-4d32-4023-d9c7-a1fff9e19fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://huggingface.co/saburbutt/xlnet_large_tweetqa"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xlnet_large_tweetqa'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC-ItvUzG1Rl",
        "outputId": "2f0a5e63-8e24-4e20-f20b-e98496a075ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#model = RobertaForQuestionAnswering.from_pretrained(\"https://huggingface.co/saburbutt/roberta_base_tweetqa_model\")\n",
        "model.save_pretrained(\"/content/xlnet_large_tweetqa\")\n",
        "tokenizer.save_pretrained(\"/content/xlnet_large_tweetqa\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/xlnet_large_tweetqa/tokenizer_config.json',\n",
              " '/content/xlnet_large_tweetqa/special_tokens_map.json',\n",
              " '/content/xlnet_large_tweetqa/spiece.model',\n",
              " '/content/xlnet_large_tweetqa/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAIHEy_I7JKN"
      },
      "source": [
        "#!git add . && git commit -m \"Update from $USER\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUmxsSEWGvAS"
      },
      "source": [
        "\n",
        "# Then commit as usual\n",
        "#!cd testing\n",
        "#!echo \"hello\" >> README.md\n",
        "\n",
        "#. && git commit -m \"Update from $USER\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AteaJnsdGiHX"
      },
      "source": [
        "#! git add \"/content/testing/config.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpZcOrv0eC8u",
        "outputId": "1802314e-f969-4429-df92-dd6894d0cf82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! git filter-branch --index-filter 'git rm -r --cached --ignore-unmatch <file/dir>' HEAD"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rRewrite ee26ee26e737e93a8db24e86ec4e71d7a6d1be5a (1/3) (0 seconds passed, remaining 0 predicted)    /usr/lib/git-core/git-filter-branch: 1: eval: Syntax error: end of file unexpected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q43TVoAb9bJj",
        "outputId": "83bff8ea-0746-4f40-b8de-4245e62fbc95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd \"/content/xlnet_large_tweetqa\"\n",
        "#!pwd\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install --force\n",
        "# !git lfs track \"*.json\"\n",
        "# !git lfs track \"*.bin\"\n",
        "# !git lfs track \"*.txt\"\n",
        "# # # #!cd \"/content/testing\"\n",
        "#!git add .gitattributes\n",
        "\n",
        "!git add --all\n",
        "!git status\n",
        "#!git push origin master\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlnet_large_tweetqa\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 0s (16.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 144786 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   config.json\u001b[m\n",
            "\t\u001b[32mnew file:   pytorch_model.bin\u001b[m\n",
            "\t\u001b[32mnew file:   special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   spiece.model\u001b[m\n",
            "\t\u001b[32mnew file:   tokenizer_config.json\u001b[m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QtWeZMGfCNS"
      },
      "source": [
        "#!git reset HEAD~2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7df9_JuAeSC",
        "outputId": "5bdb0300-14ec-4686-d06c-fa733e0799f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! git lfs install\n",
        "!git commit -m \"version1\"\n",
        "#!git config --global user.email \"saboor.butt007@gmail.com\"\n",
        "#!git config --global user.name \"saburbutt\"\n",
        "#!git pull --rebase\n",
        "!git push https://saburbutt:XXXX@huggingface.co/saburbutt/xlnet_large_tweetqa"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[main d33efec] version1\n",
            " 5 files changed, 44 insertions(+)\n",
            " create mode 100644 config.json\n",
            " create mode 100644 pytorch_model.bin\n",
            " create mode 100644 special_tokens_map.json\n",
            " create mode 100644 spiece.model\n",
            " create mode 100644 tokenizer_config.json\n",
            "Git LFS: (1 of 1 files) 1.36 GB / 1.36 GB\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 399.67 KiB | 4.93 MiB/s, done.\n",
            "Total 7 (delta 1), reused 0 (delta 0)\n",
            "To https://huggingface.co/saburbutt/xlnet_large_tweetqa\n",
            "   0ed919c..d33efec  main -> main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnmOaYcnQz-5",
        "outputId": "3805dfa0-0a5a-427a-8ea6-f2fb28930254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaConfig {\n",
              "  \"_name_or_path\": \"roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"RobertaForQuestionAnswering\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7SYow2BIXYf",
        "outputId": "b69a2407-6193-4860-89ef-b766529643c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git commit -m \"First version of the tweetqa roberta base model and tokenizer.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
