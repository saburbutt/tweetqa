{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainingtweetqa_albert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c324c0a2f5342fbbe7df54f80b9e8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd678973209d4b74bd305c2e92dd4ed6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e914ce49d6a4fb7af2a1bc35446b683",
              "IPY_MODEL_8c0867078b2545a094984d5fe59b6816"
            ]
          }
        },
        "bd678973209d4b74bd305c2e92dd4ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e914ce49d6a4fb7af2a1bc35446b683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d30b0d13722a486d85fe69d4b677b8b6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b59dc5d2f244cffa57f5de709fe891d"
          }
        },
        "8c0867078b2545a094984d5fe59b6816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cefdc79675cc48bda1bb391bac774a2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:01&lt;00:00, 608kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7ee2a7b9963415d823672e6c6bf905b"
          }
        },
        "d30b0d13722a486d85fe69d4b677b8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b59dc5d2f244cffa57f5de709fe891d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cefdc79675cc48bda1bb391bac774a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7ee2a7b9963415d823672e6c6bf905b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b58fb4a9c18b4dfba3d8d1d66c898d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7fa497ea401c40e6972c03f8cdd39ac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b32871bfef94d32a103b7ef4f9130b5",
              "IPY_MODEL_0e57bc31a4fc4f36ba4e613f7a282a3b"
            ]
          }
        },
        "7fa497ea401c40e6972c03f8cdd39ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b32871bfef94d32a103b7ef4f9130b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38e76c2ad0c94a76a6c9a82e5dab49d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1312669,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1312669,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9eb7bcef9ecf43b8b66449e609c9cc99"
          }
        },
        "0e57bc31a4fc4f36ba4e613f7a282a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a11088c8d295476bb2337ca3f26d229d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 2.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6785beb6fe6c40769b0389126f3af28f"
          }
        },
        "38e76c2ad0c94a76a6c9a82e5dab49d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9eb7bcef9ecf43b8b66449e609c9cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a11088c8d295476bb2337ca3f26d229d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6785beb6fe6c40769b0389126f3af28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bc62f8c34b34098beeef62bb6cac799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef0c5a52fc8b4fa8bb7829970994a026",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54013a936e4a48fba20f7248d9fe632d",
              "IPY_MODEL_db4d5e0b84a3477ea998116825252d92"
            ]
          }
        },
        "ef0c5a52fc8b4fa8bb7829970994a026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54013a936e4a48fba20f7248d9fe632d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fce8192fe644b0aa8eb72b2a0ad92c7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 710,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 710,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9e5663027d947638adcb085c780e1c4"
          }
        },
        "db4d5e0b84a3477ea998116825252d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aed9fcbc77fe43c89f42ce7cc74b0907",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 710/710 [00:00&lt;00:00, 1.45kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccd01ecd102d4d7e9f3b81789f55f9b6"
          }
        },
        "2fce8192fe644b0aa8eb72b2a0ad92c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9e5663027d947638adcb085c780e1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aed9fcbc77fe43c89f42ce7cc74b0907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccd01ecd102d4d7e9f3b81789f55f9b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b044c426a4bf4e528f214922d15fdf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e698b1cf0d34f59a9acbca04d160808",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_361a85890dd44db99e2cb97598323d7b",
              "IPY_MODEL_dd4c406962734fae8b539b87ee7277a2"
            ]
          }
        },
        "5e698b1cf0d34f59a9acbca04d160808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "361a85890dd44db99e2cb97598323d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20c6164deb1d4c5caa283c5dc3829d2f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 892728632,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 892728632,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67ac709162b145f29096a4b824d98dce"
          }
        },
        "dd4c406962734fae8b539b87ee7277a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1235af19b29245f780dc5f186a7c2dc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 893M/893M [00:18&lt;00:00, 49.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cff29773ca19438da2352acbc5dd9d63"
          }
        },
        "20c6164deb1d4c5caa283c5dc3829d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67ac709162b145f29096a4b824d98dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1235af19b29245f780dc5f186a7c2dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cff29773ca19438da2352acbc5dd9d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saburbutt/tweetqa/blob/master/trainingtweetqa_albert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_YvqmuAVv7D",
        "outputId": "a6ab1fcf-2067-462d-8116-51cfaf6aaac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install transformers\n",
        "! pip install torch\n",
        "#%cd \"/content/albert_xxlarge_tweetqa\"\n",
        "! pip install git-lfs install\n",
        "#!git lfs install"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "/content/albert_xxlarge_tweetqa\n",
            "Requirement already satisfied: git-lfs in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.6/dist-packages (1.3.4)\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--tnazUPWZNT",
        "outputId": "dc136420-0a91-4b56-c9fa-1ac601c2ae42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! transformers-cli login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 18:30:50.248625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: saboor.butt007@gmail.com\n",
            "Password: \n",
            "Login successful\n",
            "Your token: lNqOTtqpnkgTvsvOZOoRlolpSilcLZrBHmfUkSZHBSaknMTdOXVQgJvOdGoEoVYseVSJbMvGAHJLzOYPhhecvoxNqeKUixIOgQAtNVffPKItqEERFbItErQYiIqoQkRv \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxOguxuIcwtJ"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "      squad_dict = json.load(f)\n",
        "    \n",
        "  \n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    \"\"\"for qs in squad_dict[\"data\"]:\n",
        "      for qas in qs[\"paragraphs\"]:\n",
        "        #print(qas[\"context\"])\n",
        "        #print(qas)\n",
        "        context = qas['context']\n",
        "        #print(context)\n",
        "        for quest in qas['qas']:\n",
        "          print(quest)\"\"\"\n",
        "         \n",
        "        \n",
        "    #question = qs[\"Question\"]\n",
        "    #answer = qs[\"Answer\"]\n",
        "    #context = qs[\"Tweet\"]\n",
        "    #print(question, answer[0:], context)\n",
        "    #contexts.append((qs[\"Tweet\"])\n",
        "    #questions.append(qs[\"Question\"])\n",
        "    #answers.append(qs[\"Answer\"])\n",
        "      \n",
        "    \n",
        "    \n",
        "    \n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "  \n",
        "\n",
        "#train_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3ZjCyqYGmGw",
        "outputId": "8827e97d-806f-4de1-ed5b-4b7838168d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "\"\"\"import json\n",
        "from pathlib import Path\n",
        "\n",
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "train_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import json\\nfrom pathlib import Path\\n\\ndef read_squad(path):\\n    path = Path(path)\\n    with open(path, 'rb') as f:\\n        squad_dict = json.load(f)\\n\\n    contexts = []\\n    questions = []\\n    answers = []\\n    for group in squad_dict['data']:\\n        for passage in group['paragraphs']:\\n            context = passage['context']\\n            for qa in passage['qas']:\\n                question = qa['question']\\n                for answer in qa['answers']:\\n                    contexts.append(context)\\n                    questions.append(question)\\n                    answers.append(answer)\\n\\n    return contexts, questions, answers\\n\\ntrain_contexts, train_questions, train_answers = read_squad('train-v2.0.json')\\nval_contexts, val_questions, val_answers = read_squad('dev-v2.0.json')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnLWnos6FGqd",
        "outputId": "2857bed0-0773-4b1d-d380-16854aa874be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"print(train_contexts[0])\n",
        "print(train_questions[0])\n",
        "print(train_answers[0])\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print(train_contexts[0])\\nprint(train_questions[0])\\nprint(train_answers[0])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQlttoPOSpUO",
        "outputId": "a7db0cc2-9948-447b-c9db-80b0cf2f6116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(val_contexts[0])\n",
        "print(val_questions[0])\n",
        "print(val_answers[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
            "In what country is Normandy located?\n",
            "{'text': 'France', 'answer_start': 159}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ENYEcr7SspA"
      },
      "source": [
        "import json\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ucBE35HSumO"
      },
      "source": [
        "def extract_element_from_json(obj, path):\n",
        "    '''\n",
        "    Extracts an element from a nested dictionary or\n",
        "    a list of nested dictionaries along a specified path.\n",
        "    If the input is a dictionary, a list is returned.\n",
        "    If the input is a list of dictionary, a list of lists is returned.\n",
        "    obj - list or dict - input dictionary or list of dictionaries\n",
        "    path - list - list of strings that form the path to the desired element\n",
        "    '''\n",
        "    def extract(obj, path, ind, arr):\n",
        "        '''\n",
        "            Extracts an element from a nested dictionary\n",
        "            along a specified path and returns a list.\n",
        "            obj - dict - input dictionary\n",
        "            path - list - list of strings that form the JSON path\n",
        "            ind - int - starting index\n",
        "            arr - list - output list\n",
        "        '''\n",
        "        key = path[ind]\n",
        "        if ind + 1 < len(path):\n",
        "            if isinstance(obj, dict):\n",
        "                if key in obj.keys():\n",
        "                    extract(obj.get(key), path, ind + 1, arr)\n",
        "                else:\n",
        "                    arr.append(None)\n",
        "            elif isinstance(obj, list):\n",
        "                if not obj:\n",
        "                    arr.append(None)\n",
        "                else:\n",
        "                    for item in obj:\n",
        "                        extract(item, path, ind, arr)\n",
        "            else:\n",
        "                arr.append(None)\n",
        "        if ind + 1 == len(path):\n",
        "            if isinstance(obj, list):\n",
        "                if not obj:\n",
        "                    arr.append(None)\n",
        "                else:\n",
        "                    for item in obj:\n",
        "                        arr.append(item.get(key, None))\n",
        "            elif isinstance(obj, dict):\n",
        "                arr.append(obj.get(key, None))\n",
        "            else:\n",
        "                arr.append(None)\n",
        "        return arr\n",
        "    if isinstance(obj, dict):\n",
        "        return extract(obj, path, 0, [])\n",
        "    elif isinstance(obj, list):\n",
        "        outer_arr = []\n",
        "        for item in obj:\n",
        "            outer_arr.append(extract(item, path, 0, []))\n",
        "        return outer_arr\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiuX1fgRSwq2"
      },
      "source": [
        "def list_flatten(l):\n",
        "    result = list()\n",
        "    for item in l:\n",
        "        if isinstance(item, (list, tuple)):\n",
        "            result.extend(item)\n",
        "        else:\n",
        "            result.append(item)\n",
        "    return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MVpHr2oSyao"
      },
      "source": [
        "class All_Data:  \n",
        "    def __init__(self, qas, context):  \n",
        "        self.qas = qas\n",
        "        self.context = context\n",
        "\n",
        "        \n",
        "class Questions:  \n",
        "    def __init__(self, question, answer, _id, is_impossible ):  \n",
        "        self.question = question  \n",
        "        self._id = _id \n",
        "        self.answer = answer \n",
        "        self.is_impossible = is_impossible\n",
        "                \n",
        "\n",
        "class Answers:  \n",
        "    def __init__(self, text, answer_start):  \n",
        "        self.text = text  \n",
        "        self.answer_start = answer_start     \n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BRNPspS08m",
        "outputId": "0fc474b9-f2b2-480e-c533-36a47a311536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "with open('results.json', 'r') as file:\n",
        "    all_data = json.load(file)\n",
        "    print(len(all_data))\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWAVVCZsS5LJ"
      },
      "source": [
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "\n",
        "counting = 0\n",
        "\n",
        "for data in all_data:\n",
        "    context = ''.join(extract_element_from_json(data, [\"context\"]))\n",
        "    que = list_flatten(list_flatten(extract_element_from_json(data, [\"qas\"])))\n",
        "\n",
        "    for q in que:\n",
        "        ans = extract_element_from_json(q, [\"answer\"])\n",
        "        #print(ans)\n",
        "        for a in ans:\n",
        "            #print(a['text'])\n",
        "            #print(a['answer_start'])\n",
        "            if not a['answer_start'] == 0:\n",
        "                #print(context.lower())\n",
        "                #print(q['question'].lower())\n",
        "                #print(q['answer'])\n",
        "                contexts.append(context.lower())\n",
        "                questions.append(q['question'].lower())\n",
        "                answers.append(q['answer'])\n",
        "            \n",
        "\n",
        "    #print(\"\\n\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzLBOMwTS7Nw"
      },
      "source": [
        "train_contexts = contexts\n",
        "train_questions = questions\n",
        "train_answers = answers"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bMgS8XS83H",
        "outputId": "8e8c17f5-315d-40a2-873a-6dbc95e2bc32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_contexts[0])\n",
        "print(train_questions[0])\n",
        "print(train_answers[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our prayers are with the students, educators & families at independence high school & all the first responders on the scene. #patriotprideâ€” doug ducey (@dougducey) february 12, 2016\n",
            "at which school were first responders on the scene for?\n",
            "{'text': 'independence high school', 'answer_start': 59}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhavDW55At59"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UAWEpQ1dygO"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        #print(answer['text'])\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "        #print(gold_text)\n",
        "        #print(start_idx)\n",
        "        #print(end_idx)\n",
        "        #print(\"\\n\")\n",
        "\n",
        "        # sometimes squad answers are off by a character or two â€“ fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo5s9XnEd5ld",
        "outputId": "ef737403-992b-4835-8929-1bea292c4319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "3c324c0a2f5342fbbe7df54f80b9e8a5",
            "bd678973209d4b74bd305c2e92dd4ed6",
            "6e914ce49d6a4fb7af2a1bc35446b683",
            "8c0867078b2545a094984d5fe59b6816",
            "d30b0d13722a486d85fe69d4b677b8b6",
            "3b59dc5d2f244cffa57f5de709fe891d",
            "cefdc79675cc48bda1bb391bac774a2e",
            "c7ee2a7b9963415d823672e6c6bf905b",
            "b58fb4a9c18b4dfba3d8d1d66c898d47",
            "7fa497ea401c40e6972c03f8cdd39ac6",
            "3b32871bfef94d32a103b7ef4f9130b5",
            "0e57bc31a4fc4f36ba4e613f7a282a3b",
            "38e76c2ad0c94a76a6c9a82e5dab49d1",
            "9eb7bcef9ecf43b8b66449e609c9cc99",
            "a11088c8d295476bb2337ca3f26d229d",
            "6785beb6fe6c40769b0389126f3af28f"
          ]
        }
      },
      "source": [
        "#from transformers import DistilBertTokenizerFast\n",
        "from transformers import AlbertTokenizerFast\n",
        "#from transformers import XLNetTokenizerFast\n",
        "#from transformers import RobertaTokenizerFast\n",
        "#from transformers import XLMRobertaTokenizerFast\n",
        "import torch\n",
        "#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "#tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "#tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-xxlarge-v2')\n",
        "#tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")\n",
        "#tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-large\")\n",
        "#xlm-roberta-large\n",
        "#tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-large-cased')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c324c0a2f5342fbbe7df54f80b9e8a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b58fb4a9c18b4dfba3d8d1d66c898d47",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnlCx12AFyKQ",
        "outputId": "df79e5c3-3ffe-4b3e-c2c1-fca24166f5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_encodings[0])\n",
        "print(val_encodings[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding(num_tokens=106, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXO_rEpueH6O"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        #print(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        #print(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        # if None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "        #print(\"\\n\")\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkLAW7jeUXS"
      },
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ5Ldsamewug",
        "outputId": "6ca13f90-2066-4b94-bafb-47d4595a70cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "6bc62f8c34b34098beeef62bb6cac799",
            "ef0c5a52fc8b4fa8bb7829970994a026",
            "54013a936e4a48fba20f7248d9fe632d",
            "db4d5e0b84a3477ea998116825252d92",
            "2fce8192fe644b0aa8eb72b2a0ad92c7",
            "b9e5663027d947638adcb085c780e1c4",
            "aed9fcbc77fe43c89f42ce7cc74b0907",
            "ccd01ecd102d4d7e9f3b81789f55f9b6",
            "b044c426a4bf4e528f214922d15fdf97",
            "5e698b1cf0d34f59a9acbca04d160808",
            "361a85890dd44db99e2cb97598323d7b",
            "dd4c406962734fae8b539b87ee7277a2",
            "20c6164deb1d4c5caa283c5dc3829d2f",
            "67ac709162b145f29096a4b824d98dce",
            "1235af19b29245f780dc5f186a7c2dc8",
            "cff29773ca19438da2352acbc5dd9d63"
          ]
        }
      },
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "from transformers import AlbertForQuestionAnswering\n",
        "from transformers import XLNetForQuestionAnswering\n",
        "from transformers import RobertaForQuestionAnswering\n",
        "from transformers import XLMRobertaForQuestionAnswering\n",
        "#model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
        "#model = AlbertForQuestionAnswering.from_pretrained('albert-large-v2')\n",
        "model = AlbertForQuestionAnswering.from_pretrained('albert-xxlarge-v2')\n",
        "#model = XLNetForQuestionAnswering.from_pretrained('xlnet-base-cased')\n",
        "#model = RobertaForQuestionAnswering.from_pretrained('roberta-base' , from_tf=True)\n",
        "#model = XLNetForQuestionAnswering.from_pretrained('xlnet-large-cased')\n",
        "#model = RobertaForQuestionAnswering.from_pretrained('roberta-large')\n",
        "#model = XLMRobertaForQuestionAnswering.from_pretrained('xlm-roberta-large')\n",
        "#xlm-roberta-large\n",
        "#roberta-large\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bc62f8c34b34098beeef62bb6cac799",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=710.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b044c426a4bf4e528f214922d15fdf97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=892728632.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForQuestionAnswering: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-xxlarge-v2 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNPJTqzZfys7",
        "outputId": "c49ee5cf-2188-4198-ba94-5a9620242cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0.alpha0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79.9MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.18.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.33.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 419kB 70.3MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.10.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0.alpha0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0.alpha0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0.alpha0) (3.4.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-applications, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Y-vBp1e1NR",
        "outputId": "3a4404e7-f800-4154-9e71-f59f0df2bf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "i = 0\n",
        "for epoch in range(3):\n",
        "    for batch in train_loader:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 10 == 0:\n",
        "          print(i, \"Done\")\n",
        "        i = i + 1\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "0 Done\n",
            "10 Done\n",
            "20 Done\n",
            "30 Done\n",
            "40 Done\n",
            "50 Done\n",
            "60 Done\n",
            "70 Done\n",
            "80 Done\n",
            "90 Done\n",
            "100 Done\n",
            "110 Done\n",
            "120 Done\n",
            "130 Done\n",
            "140 Done\n",
            "150 Done\n",
            "160 Done\n",
            "170 Done\n",
            "180 Done\n",
            "190 Done\n",
            "200 Done\n",
            "210 Done\n",
            "220 Done\n",
            "230 Done\n",
            "240 Done\n",
            "250 Done\n",
            "260 Done\n",
            "270 Done\n",
            "280 Done\n",
            "290 Done\n",
            "300 Done\n",
            "310 Done\n",
            "320 Done\n",
            "330 Done\n",
            "340 Done\n",
            "350 Done\n",
            "360 Done\n",
            "370 Done\n",
            "380 Done\n",
            "390 Done\n",
            "400 Done\n",
            "410 Done\n",
            "420 Done\n",
            "430 Done\n",
            "440 Done\n",
            "450 Done\n",
            "460 Done\n",
            "470 Done\n",
            "480 Done\n",
            "490 Done\n",
            "500 Done\n",
            "510 Done\n",
            "520 Done\n",
            "530 Done\n",
            "540 Done\n",
            "550 Done\n",
            "560 Done\n",
            "570 Done\n",
            "580 Done\n",
            "590 Done\n",
            "600 Done\n",
            "610 Done\n",
            "620 Done\n",
            "630 Done\n",
            "640 Done\n",
            "650 Done\n",
            "660 Done\n",
            "670 Done\n",
            "680 Done\n",
            "690 Done\n",
            "700 Done\n",
            "710 Done\n",
            "720 Done\n",
            "730 Done\n",
            "740 Done\n",
            "750 Done\n",
            "760 Done\n",
            "770 Done\n",
            "780 Done\n",
            "790 Done\n",
            "800 Done\n",
            "810 Done\n",
            "820 Done\n",
            "830 Done\n",
            "840 Done\n",
            "850 Done\n",
            "860 Done\n",
            "870 Done\n",
            "880 Done\n",
            "890 Done\n",
            "900 Done\n",
            "910 Done\n",
            "920 Done\n",
            "930 Done\n",
            "940 Done\n",
            "950 Done\n",
            "960 Done\n",
            "970 Done\n",
            "980 Done\n",
            "990 Done\n",
            "1000 Done\n",
            "1010 Done\n",
            "1020 Done\n",
            "1030 Done\n",
            "1040 Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForQuestionAnswering(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=4096, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((4096,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "                (key): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "                (value): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "                (LayerNorm): LayerNorm((4096,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "              (ffn_output): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=4096, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMHtgaUAXJaQ"
      },
      "source": [
        "# Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejtiRpQ1tn5N",
        "outputId": "be18fe21-16fd-490d-a757-e0be1dbf9767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"! pip install joblib\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'! pip install joblib'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTadVwCLvtKi",
        "outputId": "4d6068e8-bb74-4d93-a213-62d6a3313a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"import joblib\n",
        "filename = 'xlm-roberta_large_tweetqa_model.sav'\n",
        "joblib.dump(model, filename)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import joblib\\nfilename = 'xlm-roberta_large_tweetqa_model.sav'\\njoblib.dump(model, filename)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJr46lg-CAS",
        "outputId": "6fd06fa3-117f-4155-9334-09233b2fc503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! transformers-cli repo create albert_xxlarge_tweetqa\n",
        "#! transformers-cli repo ls-files testing"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 19:08:38.801429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[90mgit version 2.17.1\u001b[0m\n",
            "\u001b[1m\u001b[31mLooks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once).\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1msaburbutt/albert_xxlarge_tweetqa\u001b[0m\n",
            "Proceed? [Y/n] Y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/saburbutt/albert_xxlarge_tweetqa\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/saburbutt/albert_xxlarge_tweetqa\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaerK0u5TWm",
        "outputId": "7b027117-beb4-47e5-9a16-dc5ac67781ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!git clone https://huggingface.co/saburbutt/albert_xxlarge_tweetqa"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'albert_xxlarge_tweetqa'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC-ItvUzG1Rl",
        "outputId": "af523c1a-3906-4486-834a-ad73c8862915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#model = RobertaForQuestionAnswering.from_pretrained(\"https://huggingface.co/saburbutt/roberta_base_tweetqa_model\")\n",
        "model.save_pretrained(\"/content/albert_xxlarge_tweetqa\")\n",
        "tokenizer.save_pretrained(\"/content/albert_xxlarge_tweetqa\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/albert_xxlarge_tweetqa/tokenizer_config.json',\n",
              " '/content/albert_xxlarge_tweetqa/special_tokens_map.json',\n",
              " '/content/albert_xxlarge_tweetqa/spiece.model',\n",
              " '/content/albert_xxlarge_tweetqa/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAIHEy_I7JKN"
      },
      "source": [
        "#!git add . && git commit -m \"Update from $USER\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUmxsSEWGvAS"
      },
      "source": [
        "\n",
        "# Then commit as usual\n",
        "#!cd testing\n",
        "#!echo \"hello\" >> README.md\n",
        "\n",
        "#. && git commit -m \"Update from $USER\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AteaJnsdGiHX"
      },
      "source": [
        "#! git add \"/content/testing/config.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpZcOrv0eC8u",
        "outputId": "1802314e-f969-4429-df92-dd6894d0cf82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git filter-branch --index-filter 'git rm -r --cached --ignore-unmatch <file/dir>' HEAD"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rRewrite ee26ee26e737e93a8db24e86ec4e71d7a6d1be5a (1/3) (0 seconds passed, remaining 0 predicted)    /usr/lib/git-core/git-filter-branch: 1: eval: Syntax error: end of file unexpected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q43TVoAb9bJj",
        "outputId": "82af0f02-3bbe-4d77-fb54-5190060b4b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd \"/content/albert_xxlarge_tweetqa\"\n",
        "#!pwd\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install --force\n",
        "# !git lfs track \"*.json\"\n",
        "# !git lfs track \"*.bin\"\n",
        "# !git lfs track \"*.txt\"\n",
        "# # # #!cd \"/content/testing\"\n",
        "#!git add .gitattributes\n",
        "\n",
        "!git add --all\n",
        "!git status\n",
        "#!git push origin master\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/albert_xxlarge_tweetqa\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   config.json\u001b[m\n",
            "\t\u001b[32mnew file:   pytorch_model.bin\u001b[m\n",
            "\t\u001b[32mnew file:   special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   spiece.model\u001b[m\n",
            "\t\u001b[32mnew file:   tokenizer_config.json\u001b[m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QtWeZMGfCNS"
      },
      "source": [
        "#!git reset HEAD~2"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7df9_JuAeSC",
        "outputId": "4ad93f4c-f603-4d66-f286-649436cadcc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#! git lfs install\n",
        "!git commit -m \"version1\"\n",
        "!git config --global user.email \"saboor.butt007@gmail.com\"\n",
        "!git config --global user.name \"saburbutt\"\n",
        "!git pull --rebase\n",
        "!git push https://saburbutt:XXXX@huggingface.co/saburbutt/albert_xxlarge_tweetqa"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[main 1812bd6] version1\n",
            " 5 files changed, 36 insertions(+)\n",
            " create mode 100644 config.json\n",
            " create mode 100644 pytorch_model.bin\n",
            " create mode 100644 special_tokens_map.json\n",
            " create mode 100644 spiece.model\n",
            " create mode 100644 tokenizer_config.json\n",
            "Current branch main is up to date.\n",
            "Git LFS: (0 of 0 files, 1 skipped) 0 B / 0 B, 785.16 MB skippedCounting objects: 7, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 380.78 KiB | 5.08 MiB/s, done.\n",
            "Total 7 (delta 0), reused 0 (delta 0)\n",
            "To https://huggingface.co/saburbutt/albert_xxlarge_tweetqa\n",
            "   ee26ee2..1812bd6  main -> main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnmOaYcnQz-5",
        "outputId": "3805dfa0-0a5a-427a-8ea6-f2fb28930254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaConfig {\n",
              "  \"_name_or_path\": \"roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"RobertaForQuestionAnswering\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7SYow2BIXYf",
        "outputId": "b69a2407-6193-4860-89ef-b766529643c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git commit -m \"First version of the tweetqa roberta base model and tokenizer.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
